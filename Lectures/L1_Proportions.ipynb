{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1bcfda3",
   "metadata": {},
   "source": [
    "# L1 Computing the Proportion\n",
    "\n",
    "To begin, we will focus on one of the fundamental building blocks: calculating the proportion. I chose to start with the proportion as (1) it is simple to understand, (2) it can be easily be computed by hand, and (3) it naturally builds up to more complex measures.\n",
    "\n",
    "In words, the proportion is share of events for a well-defined group. Below is the formula for the proportion of $n$ individuals whose $Y_i = 1$\n",
    "\n",
    "$$ \\hat{\\mu} = \\frac{1}{n} \\sum_i^n I(Y_i = 1)$$\n",
    "\n",
    "The proportion in this context might be important to compute as it can be used to estimate the probability, $\\mu$, for a population. To connect the estimand ($\\mu$) and the estimate ($\\hat{\\mu}$), we adopt a large-sample framework, and make the following assumptions: the $n$ units are a random sample of the population (and are only a small percent of the total population), no measurement error of $Y$, and no missing values of $Y$. Under these assumptions, we can estimate the probability using the proportion formula above.\n",
    "\n",
    "With these assumptions made, now the question becomes how can be compute $\\hat{\\mu}$. The rest of the tutorial focuses on this computational task. \n",
    "\n",
    "## 1.0 Setup\n",
    "\n",
    "For this tutorial, we will use 3 free and open-source software (FOSS) libraries. These are `NumPy`, `SciPy`, and `matplotlib`. `NumPy` is used to basic numerical operations with arrays, `SciPy` will be used for some pre-built optimization functions, and `matplotlib` will be used to create plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82370df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c66608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions\n",
      "------------------\n",
      "NumPy     : 1.25.2\n",
      "SciPy     : 1.11.2\n",
      "matplotlib: 3.5.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Versions\")\n",
    "print(\"------------------\")\n",
    "print('NumPy     :', np.__version__)\n",
    "print('SciPy     :', sp.__version__)\n",
    "print('matplotlib:', matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14471cf5",
   "metadata": {},
   "source": [
    "For all the following examples, we will use the following data. The data consists of 60 observations with 20 events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a26b60f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_array = np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                    1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                    1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                    1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2371141a",
   "metadata": {},
   "source": [
    "## 1.1 Closed-form\n",
    "First, we will consider the easiest and most computationally efficient way to compute the proportion: the closed-form. The formula for $\\hat{\\mu}$ above is a *closed-form* solution, in that we can directly compute the proportion from the number of events and number of observations. The proportion (i.e., estimator for the probability) is simply requires us to count up the number of events divided by the total number of units. \n",
    "\n",
    "To begin, we will manually compute the number of events and number of observations. While not the most efficient, we will use a `for` loop here to calculate. Specifically, we will keep count of the number of observations we have seen. Then we will also keep track of the number of events that occur. Below is code to accomplish this approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b85584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closed_form_byhand(y):\n",
    "    total_n_obs = 0                             # Initialize number of observations as zero\n",
    "    total_events = 0                            # Initialize number of events as zero\n",
    "\n",
    "    for yi in y:                                # For loop through each Y_i value in the array\n",
    "        total_n_obs = total_n_obs + 1           # ... add 1 to the number of observations counter\n",
    "        if yi == 1:                             # ... if Y_i = 1 (i.e., is an event),\n",
    "            total_events = total_events + 1     # ... then add 1 to the number of events counter\n",
    "\n",
    "    # Closed-form formula with for-loop counts\n",
    "    mu = total_events / total_n_obs\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cd5d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_closedform = closed_form_byhand(y=y_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c41b2eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(mu_closedform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de566d3",
   "metadata": {},
   "source": [
    "While the code above works, it is slow (as it uses a `for` loop) and is a lot of code to complete such a basic task. Instead, let's use some built-in functionalities. We will use the `len` function to compute the number of observations and the `np.sum` function to count up the number of events (1's)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85682555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closed_form_quick(y):\n",
    "    event_obs = np.sum(y == 1)   # Number of events\n",
    "    total_obs = len(y)           # Number of observations\n",
    "    mu = event_obs / total_obs   # Closed-form formula\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dfd38c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_closedform = closed_form_quick(y=y_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5eb0800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(mu_closedform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189da037",
   "metadata": {},
   "source": [
    "As we can see above, we end up with the same answer for both approaches. This is reassuring and highlights an important lesson: implementing equivalent computational procedures in different ways is a useful check. \n",
    "\n",
    "While the closed-form is computationally efficient and simple to implement for the proportion, closed-form solutions will not always be an option when we get to more complex problems. Therefore, we consider other ways we could compute the mean.\n",
    "\n",
    "## 1.2 Maximization\n",
    "\n",
    "Another option is to use maximum likelihood estimation. Briefly, the likelihood is the joint probability of the observed values of $Y$ given $\\mu$. The likelihood is denoted as \n",
    "\n",
    "$$ \\mathcal{L}(\\mu | y)$$\n",
    "\n",
    "where $y$ is a realization of the random variable $Y$. To estimate $\\hat{\\mu}$, we can find the value of $\\mu$ that *maximizes* the likelihood give the observed data. Here, we have a binary event. As such, we will assume a Bernoulli distribution. The likelihood is therefore\n",
    "\n",
    "$$ \\mathcal{L}(\\mu | y) = \\prod_{i=1}^n \\begin{pmatrix} n \\\\ y \\end{pmatrix} \\mu^{Y_i} \\left(1 - \\mu \\right)^{1 - Y_i}$$\n",
    "\n",
    "As the first term is a constant given the data, we can safely ignore it for our maximization procedure. Therefore, we we only need to maximize \n",
    "\n",
    "$$ \\mathcal{L}(\\mu | y) = \\prod_{i=1}^n \\mu^{Y_i} \\left(1 - \\mu \\right)^{1 - Y_i}$$\n",
    "\n",
    "However, this likelihood suffers from a computational issue. When multiplying numbers is harder for the computer than summing values. Therefore, we will maximize the *log-transformed* likelihood instead, which is a series of additions rather than multiplications. Importantly, the maximum of the log-likelihood is the same as the likelihood. \n",
    "\n",
    "The log-likelihood is\n",
    "\n",
    "$$ \\mathcal{l}(\\mu | y) = \\sum_{i=1}^n \\left[Y_i \\log(\\mu) + \\left(1 - Y_i\\right) \\log\\left(1 - \\mu \\right) \\right]$$\n",
    "\n",
    "Using this equation, we can estimate the proportion by finding the value of $\\hat{\\mu}$ that maximizes this equation. In the machine learning world, we would call this function the *objective function*. Now we can consider how to find the parameter values that maximize this equation.\n",
    "\n",
    "Before we do that, let's translate this equation into code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d4bfc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood_individual(mu):\n",
    "    # Array of individual contributions to log-likelihood\n",
    "    return y_array*np.log(mu) + (1-y_array)*np.log(1-mu)\n",
    "\n",
    "def log_likelihood_proportion(mu):\n",
    "    logl_i = log_likelihood_individual(mu=mu)   # Individual contribution\n",
    "    logl = np.sum(logl_i)                       # Log-likelihood\n",
    "    return logl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13b6482",
   "metadata": {},
   "source": [
    "Now the trick is determining how to maximize the log-likelihood. \n",
    "\n",
    "Some algorithms we will use instead *minimize* the objective function. As a result, we often need to instead *minimize* the *negative* log-likelihood, which is equivalent as maximizing the log-likelihood. The following function applies the negative transformation for us that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8158866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_likelihood(mu):\n",
    "    logl = log_likelihood_proportion(mu=mu)\n",
    "    return -1*logl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efbeb3f",
   "metadata": {},
   "source": [
    "Having set up everything, we can now consider different approaches to optimizing this function. \n",
    "\n",
    "### 1.2.1 Grid-Search\n",
    "\n",
    "The simplest approach is to conduct a grid-search over the possible values of $\\hat{\\mu}$ and find which one gives us the smallest negative log-likelihood. \n",
    "\n",
    "Important to this approach is that we assume that $\\hat{\\mu}$ is between the starting values of our grid search. In the case of the proportion and starting our grid at $[0,1]$, we are reliably assume this.\n",
    "\n",
    "The following bit of code implements a basic grid search. Note that our grid search has an error tolerance. One the scale of our grid goes below this threshold, we stop our procedure and return the best value of $\\hat{\\mu}$ our procedure found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9aac3fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_min(loglikelihood, tolerance):\n",
    "    initial_grid = np.linspace(1e-15, 1-1e-15, num=12)\n",
    "    current_grid_width = initial_grid[1] - initial_grid[0]\n",
    "\n",
    "    # Conducting grid search until below tolerance\n",
    "    while current_grid_width > tolerance:\n",
    "        grid_evaluations = []\n",
    "        for grid_value in initial_grid:\n",
    "            eval_grid_logl = loglikelihood(mu=grid_value)\n",
    "            grid_evaluations.append(eval_grid_logl)\n",
    "            \n",
    "        # Finding min evaluation\n",
    "        min_index = np.argmin(grid_evaluations)  \n",
    "        mu_first = initial_grid[min_index]\n",
    "\n",
    "        # Finding second min evaluation\n",
    "        del grid_evaluations[min_index]\n",
    "        min2_index = np.argmin(grid_evaluations)  \n",
    "        initial_grid = list(initial_grid)\n",
    "        del initial_grid[min_index]\n",
    "        mu_second = initial_grid[min2_index]\n",
    "        \n",
    "        # Creating new grid\n",
    "        initial_grid = np.linspace(mu_first, mu_second, num=12)\n",
    "        \n",
    "        # Updating parameters\n",
    "        current_grid_width = np.abs(initial_grid[1] - initial_grid[0])\n",
    "    \n",
    "    return mu_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9bac784",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_grid = grid_search_min(loglikelihood=neg_log_likelihood, \n",
    "                          tolerance=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a15f2c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33358377160030084\n"
     ]
    }
   ],
   "source": [
    "print(mu_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447eac4d",
   "metadata": {},
   "source": [
    "As we can see, there is substantial error. That is because our approach is not *exact*. Instead we have a pre-specified error tolerance and our algorithm terminates once that threshold is met. To get a better approximation, we can lower the error tolerance level. The following applies a smaller tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b24fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_grid = grid_search_min(loglikelihood=neg_log_likelihood, \n",
    "                          tolerance=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30332a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33333333641661783\n"
     ]
    }
   ],
   "source": [
    "print(mu_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538b230e",
   "metadata": {},
   "source": [
    "As seen, our answer is closer to 1/3. \n",
    "\n",
    "While a grid-search does work in this case, it is quite computationally intensive (as we have to consider whole grids of values) and doesn't easily generalize to settings with more than 1 parameter. Therefore, we consider more flexible alternatives.\n",
    "\n",
    "### 1.2.2 Nelder-Mead\n",
    "\n",
    "As the first alternative, we will use the Nelder-Mead algorithm. Here, we will use SciPy which provides Nelder-Mead and other maximization algorithms. These are implemented using very fast algorithms. Below illustrates how to apply this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17041063",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_nm = sp.optimize.minimize(neg_log_likelihood,    # Likelihood to minimize\n",
    "                             x0=0.5,                # Starting values\n",
    "                             method='Nelder-Mead',  # Method to use for min\n",
    "                             tol=1e-9)              # Tolerance for covergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1303ab0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33333334]\n"
     ]
    }
   ],
   "source": [
    "print(mu_nm.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9030520",
   "metadata": {},
   "source": [
    "Here our answer is close to 1/3 again.\n",
    "\n",
    "### 1.2.3 Monte Carlo\n",
    "\n",
    "Monte Carlo procedures are an alternative option for finding the maximum (or minimum) of a function. However, they have distinct operations from the previous methods. These methods are also common in Bayesian estimation. Regardless, this approach still focuses on maximizing the log-likelihood.\n",
    "\n",
    "Before we get to the code, let's go over an outline of Monte Carlo methods. Here, we are going to use a Metropolis sampling procedure. There are alternative mechanisms one can consider but Metropolis will work well here and is simple to implement. \n",
    "\n",
    "Essentially, we are going to take the parameter from the previous iteration and update it (using the candidate function defined above). Then we are going to evaluate the log-likelihood at the current parameter value and the proposed parameter value. Next, we calculate the probability of accepting the new proposed value. The probability of accepting the new value is based on the exponentiated difference in the log-likelihood. Finally, we resolve that probability to either keep the new value or the previous value. \n",
    "\n",
    "Because this is a probability, we will sometimes accept worse values, but this is okay for our purposes. As we will see, this allows the Monte Carlo to 'bounce' around values that are plausible for the likelihood. \n",
    "\n",
    "First, we will define a method to sample a new candidate value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "042da737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler_candidate(beta, rng):\n",
    "    candidates = rng.normal(beta, scale=0.01)\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a19eaf",
   "metadata": {},
   "source": [
    "The following function conducts a single iteration of our Metropolis sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a3c879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_iteration(beta_init, rng):\n",
    "    # Get initial value\n",
    "    beta_prev = beta_init\n",
    "    # Get a new candidate value\n",
    "    beta_prop = sampler_candidate(beta=beta_prev, rng=rng)\n",
    "    \n",
    "    # Evaluate log-likelihood at both values\n",
    "    logl_prev = log_likelihood_individual(mu=beta_prev)\n",
    "    logl_prop = log_likelihood_individual(mu=beta_prop)\n",
    "\n",
    "    # Compute the probability of accepting the candidate\n",
    "    log_prob_accept = np.min([0, np.sum(logl_prop - logl_prev)])\n",
    "    prob_accept = np.exp(log_prob_accept)\n",
    "    \n",
    "    # Flip a coin to determine whether the accept candidate\n",
    "    accept = rng.binomial(n=1, p=prob_accept, size=1)\n",
    "    \n",
    "    # Resolve whether to accept candidate value\n",
    "    if accept == 1:\n",
    "        beta_prev = beta_prop\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # Return new value\n",
    "    return beta_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12c9745",
   "metadata": {},
   "source": [
    "Now we can wrap the function defined above to run the Metropolis sampler for a given number of iterations. We will save the values from each step (this is important for later!). It will be stored in a dictionary so we can easily pair the iteration number with the parameter value for that iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b08aae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis(init, m, prng):\n",
    "    beta = init    # Setting the initial value\n",
    "    chain = {}     # Dictionary to store chain\n",
    "    \n",
    "    # Call Monte-Carlo procedure a set number of time\n",
    "    for i in range(m):\n",
    "        beta = metropolis_iteration(beta_init=beta, rng=prng)\n",
    "        chain[i] = beta\n",
    "        \n",
    "    # Return the full chain\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f404f",
   "metadata": {},
   "source": [
    "Unlike the previous procedures, this algorithm does not have an error-tolerance convergence condition. Instead, the user-specifies a maximum number of iterations and the process continues until that number is reached. To demonstrate this distinction, we will begin with a small number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1c63eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(3992421)\n",
    "c = metropolis(init=0.8, m=250, prng=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce819db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(c.keys(), c.values(), '-')\n",
    "plt.ylabel(\"Parameter\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylim([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cda8846",
   "metadata": {},
   "source": [
    "The above plot shows the current parameter value over the iteration. As we can see, the parameter wanders around a bit (or takes a 'random walk' around the parameter space). To explore the space and gravitate to the answer, we want to run a larger number of iterations.\n",
    "\n",
    "Now, let's run the Monte Carlo procedure for a large number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6b99373",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(3992421)\n",
    "c = metropolis(init=0.8, m=100000, prng=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edf7c73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(c.keys(), c.values(), '-')\n",
    "plt.ylabel(\"Parameter\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylim([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e450f0",
   "metadata": {},
   "source": [
    "Here, we can see the space being explored. The parameter quickly leaves the starting value (0.8) as it fits poorly. Afterwards, we see the Monte Carlo procedure randomly jump around 0.3ish. \n",
    "\n",
    "To get our point estimate, we want to summarize these random walks as a single value. This can be done by calculating the mean or median of those values (ignore the circularity of needing to estimate the mean to get the proportion here). Generally, we drop the values at the start of the process since it needs to 'traverse' the space. Here, we will drop the first 1000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2e85b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3430506027472018\n"
     ]
    }
   ],
   "source": [
    "param_iters = list(c.values())[999:]\n",
    "print(np.median(param_iters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d666b40a",
   "metadata": {},
   "source": [
    "Here, we can see the point estimate is slightly different from the closed-form. This results from the simulation error. As the number of iterations $\\rightarrow \\infty$, the median or mean of the parameters should go to the closed form solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d060d84",
   "metadata": {},
   "source": [
    "### 1.2.4 Evolutionary algorithms\n",
    "\n",
    "Another class of algorithms for maximization are *evolutionary algorithms*. These algorithms are inspired by the process of evolution or natural selection. Here, we are going to implement a simple evolutionary algorithm from scratch to compute the proportion. \n",
    "\n",
    "First, let's review some essential ideas for these types of algorithms. Our algorithm is going to start with a 'population' of individuals. This 'population' is going to contain some guesses for the mean. We are then going to evaluate each individual in terms of their 'fitness', where the fitness is the performance in terms of the objective function (i.e., the log-likelihood function in this case). Those individuals who have the greatest fitness are then used to produce the next generation. The reproduction cycle is repeated for a set amount of time.\n",
    "\n",
    "To effectively search, we need the values of the inputs to change between generations. If the parents produce exact copies of themselves as children, we won't make any progress. So, we will introduce two types of variation in ou algorithm: genetic cross-over between parents and random point mutations. These allow children to vary from the parents. Therefore, we anticipate that children over successive generations will 'adapt' to finding the greatest fitness.\n",
    "\n",
    "At this point, you might be wondering how this is applied computationally. Everything so far has been described under the guise of evolution. What does the genetic material of a 'number' look like? We will use the binary representation of numbers as their 'DNA'. Two functions are provided below which convert between floating point and binary representations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7ee866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_float_to_binary(value):\n",
    "    [d] = struct.unpack(\">Q\", struct.pack(\">d\", value))\n",
    "    return '{:064b}'.format(d)\n",
    "\n",
    "\n",
    "def convert_binary_to_float(binary):\n",
    "    bf = int(binary, 2).to_bytes(8, byteorder='big')\n",
    "    return struct.unpack('>d', bf)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fde7b206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0011111111110101101101010000101100001111001001111011101100110000'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = convert_float_to_binary(1.3567)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5691e4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3567"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_binary_to_float(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5474ea",
   "metadata": {},
   "source": [
    "In the application of those functions, we can see how `1.3567` is stored as a series of 1's and 0's. That sequence of binary digits will be the 'DNA' of our number. It uniquely defines our number (in 64 bits). Different numbers of bits could also be used.\n",
    "\n",
    "Now we can described cross-overs and point mutations. A cross-over occurs when we take two parents (two strings of binary digits) and create a child whose sequence consists of the first parent up to the $k$ digit and then is followed by the remainder of digits from the second parent. Below is a function that implements this to create both possible child combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1334441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(value_1, value_2, rng):\n",
    "    # Random chance whether a cross-over occurs\n",
    "    if rng.uniform(0, 1) < crossover_rate:\n",
    "        # Selecting point where cross-over occurs\n",
    "        crossover_loc = np.random.randint(1, len(value_1) - 2)\n",
    "        ch_1 = value_1[:crossover_loc] + value_2[crossover_loc:]\n",
    "        ch_2 = value_2[:crossover_loc] + value_1[crossover_loc:]\n",
    "    # No cross-over otherwise\n",
    "    else:\n",
    "        ch_1 = parent_1\n",
    "        ch_2 = parent_2\n",
    "    return ch_1, ch_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693453ac",
   "metadata": {},
   "source": [
    "Point mutations simply flip 0 to 1 and 1 to 0 randomly. Below is a function to implement point mutations for a given mutation rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56250dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(value, rng):\n",
    "    value_list = list(value)\n",
    "    for i in range(len(value_list)):\n",
    "        if rng.uniform(0, 1) < mutation_rate:\n",
    "            value_list[i] = str(1 - int(value_list[i]))\n",
    "    return ''.join(value_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f485b41",
   "metadata": {},
   "source": [
    "The final item we need is to decide how parents are selected. Below is a function the evaluates the parents and selects the best $m$ parents from that generation. These parents will be used to create the next generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f4ea9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parents(objective_function, parents, parent_n):\n",
    "    evaluated_i = objective_function(parents[:, None])\n",
    "    evaluated = np.sum(evaluated_i, axis=1)\n",
    "\n",
    "    evaluated_no_nan = evaluated[~np.isnan(evaluated)]\n",
    "    parents_no_nan = parents[~np.isnan(evaluated)]\n",
    "    best_of_gen = np.argpartition(evaluated_no_nan, -parent_n)[-parent_n:]\n",
    "\n",
    "    parents_of_next_gen = parents_no_nan[best_of_gen]\n",
    "    return parents_of_next_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab36938d",
   "metadata": {},
   "source": [
    "Now that the basic elements of our evolutionary algorithm are defined, we can define a set of hyperparameters we will use. Each of these parameters is defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "586ea5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters\n",
    "pop_size = 100          # Number of individuals in each generation\n",
    "parent_n = 10           # Number of parents to generate next generation\n",
    "crossover_rate = 0.5    # Probability of cross-over occurring\n",
    "mutation_rate = 1 / 16  # Point mutation probability\n",
    "generations = 100       # Number of generations to run\n",
    "\n",
    "# Some starting values (slightly off the truth to showcase the algorithm)\n",
    "starting_values = np.linspace(0.4, 0.95, pop_size)\n",
    "\n",
    "# Creating a random number generation for consistency\n",
    "rng = np.random.RandomState(8419812)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6fb1c7",
   "metadata": {},
   "source": [
    "The following code implements our evolutionary algorithm. In each step of the for loop, we evaluate the current generation, select the most fit individuals, and produce offspring for the next generation. This continues for the set number of generations, like the Monte Carlo procedure. Unlike the Monte Carlo approach, the best individual in the final generation will be our point estimate of the proportion (instead of a median or mean across generations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a0f23f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zivic\\AppData\\Local\\Temp\\ipykernel_17460\\3279974742.py:3: RuntimeWarning: invalid value encountered in log\n",
      "  return y_array*np.log(mu) + (1-y_array)*np.log(1-mu)\n",
      "C:\\Users\\zivic\\AppData\\Local\\Temp\\ipykernel_17460\\3279974742.py:3: RuntimeWarning: invalid value encountered in subtract\n",
      "  return y_array*np.log(mu) + (1-y_array)*np.log(1-mu)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.33333333])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial parents at the starting values\n",
    "parents = starting_values\n",
    "\n",
    "# Running the generations\n",
    "for g in range(generations-1):\n",
    "    # Evaluating and selecting parents\n",
    "    next_gen_parents = select_parents(objective_function=log_likelihood_individual, \n",
    "                                      parents=parents,\n",
    "                                      parent_n=parent_n)\n",
    "\n",
    "    # Converting parents to their DNA sequences\n",
    "    parent_dna = [convert_float_to_binary(v) for v in next_gen_parents]\n",
    "\n",
    "    # Creating new DNA for children\n",
    "    parent_pairs = rng.randint(0, parent_n, size=2*pop_size)  # Pairing parents\n",
    "    children = []                                             # Storage for children\n",
    "    for i in range(0, pop_size, 2):\n",
    "        # Looking up parent pairs\n",
    "        parent_1 = parent_dna[parent_pairs[i]]      # Getting DNA of first parent\n",
    "        parent_2 = parent_dna[parent_pairs[i + 1]]  # Getting DNA of second parent\n",
    "        \n",
    "        # Cross-over\n",
    "        child_1, child_2 = crossover(value_1=parent_1, \n",
    "                                     value_2=parent_2,\n",
    "                                     rng=rng)\n",
    "\n",
    "        # Random point mutations\n",
    "        child_1 = mutation(child_1, rng=rng)\n",
    "        child_2 = mutation(child_2, rng=rng)\n",
    "\n",
    "        # Converting back to float\n",
    "        children.append(convert_binary_to_float(child_1))\n",
    "        children.append(convert_binary_to_float(child_2))\n",
    "    \n",
    "    # Setting children to be the next set of parents\n",
    "    parents = np.asarray(children)\n",
    "\n",
    "\n",
    "# Creating final generation of parents\n",
    "final_parent = select_parents(objective_function=log_likelihood_individual, \n",
    "                              parents=parents,\n",
    "                              parent_n=1)\n",
    "# Selecting the best parent as the point estimate for the proportion\n",
    "final_parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abe41f5",
   "metadata": {},
   "source": [
    "Our final estimate is `0.333`. However, note that it is slighly different from 1/3. Like the Monte Carlo method, this is because the algorithm is random and there is no defined stopping point. In the same way, we want to run our algorithm over many iterations to obtain a good solution. Better approximations to the proportion may be possible by (1) increasing the number of generations, (2) giving better starting values, (3) adapting the mutation or cross over rates, (4) changing the number of parents in each generation, or (5) increasing the population size in each generation. Try messing around with these hyperparameters yourself to see how performance changes.\n",
    "\n",
    "In addition to these changes, there are many variations on how evolutionary algorithms can be implemented. These variations are not reviewed here (but the above algorithm could be adapted to these variations). One of note is the selection mechanism for parents. Here, we used a simple mechanism for selection of parents (the top $x$ performing parents). In complex settings, this selection approach might get stuck in local minima. This was not a concern in our application, as there is only a single maximum, but this might be a concern in other applications.\n",
    "\n",
    "#### Further Reading\n",
    "\n",
    "Katoch S, Chauhan SS, & Kumar V. (2021). A review on genetic algorithm: past, present, and future. *Multimedia tools and applications*, 80, 8091-8126."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97cc878",
   "metadata": {},
   "source": [
    "## 1.4 Root-finding\n",
    "\n",
    "Instead of minimizing (or maximizing), another option is to rewrite the original estimator as an equation equal to zero. Then we can search for the value of $\\hat{\\mu}$ that returns a zero. For this method, we first need our estimating equation. The estimating equation is a sum over all observations that is a function of the random variable, the parameter, and is equal to zero. The estimating equation for the proportion is\n",
    "$$ \\hat{\\mu} = \\frac{\\sum_{i=1}^n I(Y_i = 1)}{n} $$\n",
    "$$ n \\hat{\\mu} = \\sum_{i=1}^n I(Y_i = 1) $$\n",
    "$$ 0 = \\sum_{i=1}^n I(Y_i = 1) - n \\hat{\\mu} $$\n",
    "$$ 0 = \\sum_{i=1}^n I(Y_i = 1) - \\sum_{i=1}^n \\hat{\\mu} $$\n",
    "$$ 0 = \\sum_{i=1}^n \\left[ I(Y_i = 1) - \\hat{\\mu} \\right] $$\n",
    "Therefore, we can find the proportion by finding the value of $\\hat{\\mu}$ that results in a zero for the above equation.\n",
    "\n",
    "For ease, I will write the estimating equation as a generic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac20e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimating_equation(mu):\n",
    "    evaluated_ee = 0\n",
    "    for yi in y_array:\n",
    "        contribution_i = yi - mu\n",
    "        evaluated_ee = evaluated_ee + contribution_i\n",
    "    return evaluated_ee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7067cee",
   "metadata": {},
   "source": [
    "In general, algorithms to solve the previous equations are called *root-finding algorithms*, as the location of the zero point for a function is called its *root*. Here, we will consider a few options for root-finding algorithms. To start, we will start with a grid search approach.\n",
    "\n",
    "### 1.4.1 Grid-Search\n",
    "\n",
    "The simplest option for searching for the value of $\\hat{\\mu}$ that returns zero is to conduct a grid-search. This will be similar to the approach used for the minimization problem, but instead we will be looking for the point closest to zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f1ac512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_grid(eequation, initial=[0, 1], tolerance=1e-9):\n",
    "    # Setup\n",
    "    left, right = initial[0], initial[1]\n",
    "    mu_left = eequation(left)\n",
    "    mu_right = eequation(right)\n",
    "    error = 999\n",
    "    \n",
    "    # Simple grid-search\n",
    "    while error > tolerance:\n",
    "        center = (left + right) / 2    # Center\n",
    "        mu_center = eequation(center)  # Function at center\n",
    "\n",
    "        # Determining new cut-points\n",
    "        if mu_center < 0:\n",
    "            if left < 0:\n",
    "                left = center\n",
    "            else:\n",
    "                right = center\n",
    "        if mu_center >= 0:\n",
    "            if left >= 0:\n",
    "                left = center\n",
    "            else:\n",
    "                right = center\n",
    "\n",
    "        # Computing updated error\n",
    "        error = np.abs(mu_center)\n",
    "\n",
    "    # Return parameter at the root\n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b35b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_root = root_grid(eequation=estimating_equation, initial=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0fe64e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333430346\n"
     ]
    }
   ],
   "source": [
    "print(mu_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3dff06",
   "metadata": {},
   "source": [
    "Important to this approach is that we assume that $\\hat{\\mu}$ is between the values. In the case of the proportion and starting our grid at $[0,1]$, we are reliably assume this. Another issue with a grid-search is that it is limited to a single parameter (okay for the proportion setting being considered). Finally, it requires computing the estimating equation for lots of different parameter values. \n",
    "\n",
    "To avoid these difficulties, we will take a brief tour through some other popular root-finding algorithms. For simplicity, we will use their SciPy implementations.\n",
    "\n",
    "### 1.4.2 Levenberg-Marquardt\n",
    "\n",
    "Here, we will use a built-in function from SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03f4f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_root = sp.optimize.root(estimating_equation, \n",
    "                           x0=0.5, \n",
    "                           method='lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "065f0863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33333333]\n"
     ]
    }
   ],
   "source": [
    "print(mu_root.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eaed0b",
   "metadata": {},
   "source": [
    "Root-finding has another important relationship to minimization algorithms. Rather than rewrite an equation, one could instead take the derivative of the function we are minimizing. The slope (derivative) at the minimum is zero. Therefore, root-finding is equivalent to minimization when functions have a single minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2afa589",
   "metadata": {},
   "source": [
    "## 1.5 Conclusions\n",
    "\n",
    "This concludes the review of optimization procedures for the proportion. There are many other algorithms out there, but we saw that all these different approaches basically gave the same answer (or same answer within a given error tolerance). The basic principles reviewed here will get you many places and can be extended in multiple ways. If interested, consider going into the further reading.\n",
    "\n",
    "The next lecture will consider ways to compute the variance for the proportion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
